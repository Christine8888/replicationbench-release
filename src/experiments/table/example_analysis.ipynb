{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResearchBench Evaluation Analysis\n",
    "\n",
    "This notebook demonstrates how to load and analyze Inspect AI evaluation logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working from: /Users/christineye/rb-release\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "src_path = Path.cwd() / \"src\"\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "from dataset.dataloader import Dataloader\n",
    "from experiments.utils.analysis import (\n",
    "    load_eval_logs_to_dataframe,\n",
    "    aggregate_runs,\n",
    "    get_model_summary_stats,\n",
    "    get_per_paper_stats\n",
    ")\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(f\"Working from: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configure Paths\n",
    "\n",
    "Update these paths to point to your evaluation logs and data directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 log directories\n",
      "  - logs/gemini-25-unmask\n",
      "  - logs/claude-37-unmask\n",
      "  - logs/claude-4-unmask\n",
      "  - logs/o3-unmask\n",
      "  - logs/o4-mini-unmask\n"
     ]
    }
   ],
   "source": [
    "base_dir = Path.cwd()\n",
    "log_dirs = [\n",
    "    # \"logs/gemini-25-syw\",\n",
    "    # \"logs/claude-37-syw\",\n",
    "    # \"logs/claude-4-syw\",\n",
    "    # \"logs/o3-syw\",\n",
    "    # \"logs/o4-mini-syw\",\n",
    "    \"logs/gemini-25-unmask\",\n",
    "    \"logs/claude-37-unmask\",\n",
    "    \"logs/claude-4-unmask\",\n",
    "    \"logs/o3-unmask\",\n",
    "    \"logs/o4-mini-unmask\",\n",
    "]\n",
    "\n",
    "existing_dirs = [d for d in log_dirs if Path(d).exists() or Path(f\"{base_dir}/{d}\").exists()]\n",
    "existing_dirs = [str(Path(f\"{base_dir}/{d}\").resolve()) if not Path(d).exists() else d for d in existing_dirs]\n",
    "\n",
    "print(f\"Found {len(existing_dirs)} log directories\")\n",
    "for d in existing_dirs:\n",
    "    print(f\"  - {d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataloader\n",
    "\n",
    "Load papers and tasks for computing difficulty-weighted scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 19 papers\n",
      "Total tasks: 107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christineye/rb-release/src/dataset/wrappers/executor.py:21: UserWarning: Executor: Ignoring deprecated browsing fields: {'needs_browsing'}\n",
      "  warnings.warn(\n",
      "/Users/christineye/rb-release/src/dataset/wrappers/dataset.py:120: UserWarning: HuggingFaceDataset (tng_hod): Found fields for other dataset types: {'url'}. These will be ignored. Check if 'kind' is set correctly.\n",
      "  warnings.warn(\n",
      "/Users/christineye/rb-release/src/dataset/wrappers/dataset.py:26: UserWarning: Dataset 'illustris simulation data' (tng_hod): Ignoring unexpected fields: {'url'}\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataloader = Dataloader(\n",
    "    task_types=[\"numeric\"],\n",
    "    load_text=False,\n",
    "    filters={\"source\": \"expert\"}\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(dataloader.papers)} papers\")\n",
    "print(f\"Total tasks: {sum(len(p.tasks) for p in dataloader.papers.values())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Evaluation Logs\n",
    "\n",
    "Load all evaluation logs into a structured DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 630 rows\n",
      "Models: ['Gemini 2.5', 'claude-37-unmask', 'claude-4-unmask', 'o3', 'o4-mini']\n",
      "Papers: 19 unique papers\n",
      "\n",
      "DataFrame structure:\n",
      "                                                                              accuracy  \\\n",
      "model      run paper         task                                                        \n",
      "Gemini 2.5 1   MUSE_outflows _summary                                              0.0   \n",
      "                             dust_reddening                                        NaN   \n",
      "                             electron_density                                      NaN   \n",
      "                             narrow_and_broad_line_decomposition_for_J080427       NaN   \n",
      "                             outflow_energetics                                    NaN   \n",
      "\n",
      "                                                                              difficulty_weighted_accuracy  \\\n",
      "model      run paper         task                                                                            \n",
      "Gemini 2.5 1   MUSE_outflows _summary                                                                  0.0   \n",
      "                             dust_reddening                                                            NaN   \n",
      "                             electron_density                                                          NaN   \n",
      "                             narrow_and_broad_line_decomposition_for_J080427                           NaN   \n",
      "                             outflow_energetics                                                        NaN   \n",
      "\n",
      "                                                                              response_rate  \\\n",
      "model      run paper         task                                                             \n",
      "Gemini 2.5 1   MUSE_outflows _summary                                                   0.6   \n",
      "                             dust_reddening                                             NaN   \n",
      "                             electron_density                                           NaN   \n",
      "                             narrow_and_broad_line_decomposition_for_J080427            NaN   \n",
      "                             outflow_energetics                                         NaN   \n",
      "\n",
      "                                                                              answered_tasks  \\\n",
      "model      run paper         task                                                              \n",
      "Gemini 2.5 1   MUSE_outflows _summary                                                    3.0   \n",
      "                             dust_reddening                                              NaN   \n",
      "                             electron_density                                            NaN   \n",
      "                             narrow_and_broad_line_decomposition_for_J080427             NaN   \n",
      "                             outflow_energetics                                          NaN   \n",
      "\n",
      "                                                                              total_tasks  \\\n",
      "model      run paper         task                                                           \n",
      "Gemini 2.5 1   MUSE_outflows _summary                                                 5.0   \n",
      "                             dust_reddening                                           NaN   \n",
      "                             electron_density                                         NaN   \n",
      "                             narrow_and_broad_line_decomposition_for_J080427          NaN   \n",
      "                             outflow_energetics                                       NaN   \n",
      "\n",
      "                                                                              input_tokens  \\\n",
      "model      run paper         task                                                            \n",
      "Gemini 2.5 1   MUSE_outflows _summary                                             427820.0   \n",
      "                             dust_reddening                                            NaN   \n",
      "                             electron_density                                          NaN   \n",
      "                             narrow_and_broad_line_decomposition_for_J080427           NaN   \n",
      "                             outflow_energetics                                        NaN   \n",
      "\n",
      "                                                                              output_tokens  \\\n",
      "model      run paper         task                                                             \n",
      "Gemini 2.5 1   MUSE_outflows _summary                                                2971.0   \n",
      "                             dust_reddening                                             NaN   \n",
      "                             electron_density                                           NaN   \n",
      "                             narrow_and_broad_line_decomposition_for_J080427            NaN   \n",
      "                             outflow_energetics                                         NaN   \n",
      "\n",
      "                                                                              reasoning_tokens  \\\n",
      "model      run paper         task                                                                \n",
      "Gemini 2.5 1   MUSE_outflows _summary                                                    783.0   \n",
      "                             dust_reddening                                                NaN   \n",
      "                             electron_density                                              NaN   \n",
      "                             narrow_and_broad_line_decomposition_for_J080427               NaN   \n",
      "                             outflow_energetics                                            NaN   \n",
      "\n",
      "                                                                              runtime_minutes  \\\n",
      "model      run paper         task                                                               \n",
      "Gemini 2.5 1   MUSE_outflows _summary                                               11.466667   \n",
      "                             dust_reddening                                               NaN   \n",
      "                             electron_density                                             NaN   \n",
      "                             narrow_and_broad_line_decomposition_for_J080427              NaN   \n",
      "                             outflow_energetics                                           NaN   \n",
      "\n",
      "                                                                             has_transcript  \\\n",
      "model      run paper         task                                                             \n",
      "Gemini 2.5 1   MUSE_outflows _summary                                                  True   \n",
      "                             dust_reddening                                            None   \n",
      "                             electron_density                                          None   \n",
      "                             narrow_and_broad_line_decomposition_for_J080427           None   \n",
      "                             outflow_energetics                                        None   \n",
      "\n",
      "                                                                              task_score  \\\n",
      "model      run paper         task                                                          \n",
      "Gemini 2.5 1   MUSE_outflows _summary                                                NaN   \n",
      "                             dust_reddening                                          0.0   \n",
      "                             electron_density                                        0.0   \n",
      "                             narrow_and_broad_line_decomposition_for_J080427         0.0   \n",
      "                             outflow_energetics                                      0.0   \n",
      "\n",
      "                                                                              task_difficulty  \n",
      "model      run paper         task                                                              \n",
      "Gemini 2.5 1   MUSE_outflows _summary                                                     NaN  \n",
      "                             dust_reddening                                               1.0  \n",
      "                             electron_density                                             1.0  \n",
      "                             narrow_and_broad_line_decomposition_for_J080427              6.0  \n",
      "                             outflow_energetics                                           1.0  \n"
     ]
    }
   ],
   "source": [
    "if not existing_dirs:\n",
    "    print(\"WARNING: No log directories found. Creating empty DataFrame.\")\n",
    "    df = pd.DataFrame()\n",
    "else:\n",
    "    df = load_eval_logs_to_dataframe(existing_dirs, dataloader)\n",
    "    print(f\"\\nLoaded {len(df)} rows\")\n",
    "    print(f\"Models: {df.index.get_level_values('model').unique().tolist()}\")\n",
    "    print(f\"Papers: {len(df.index.get_level_values('paper').unique())} unique papers\")\n",
    "    print(f\"\\nDataFrame structure:\")\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Summary Statistics\n",
    "\n",
    "Overall performance across all papers and runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MODEL SUMMARY STATISTICS ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg Accuracy</th>\n",
       "      <th>Std Accuracy</th>\n",
       "      <th>Best Accuracy</th>\n",
       "      <th>Avg Difficulty-Weighted</th>\n",
       "      <th>Best Difficulty-Weighted</th>\n",
       "      <th>Avg Response Rate</th>\n",
       "      <th>Avg Output Tokens</th>\n",
       "      <th>Avg Reasoning Tokens</th>\n",
       "      <th>Avg Runtime (min)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gemini 2.5</th>\n",
       "      <td>0.062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.430</td>\n",
       "      <td>22270.368</td>\n",
       "      <td>2575.263</td>\n",
       "      <td>172.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-37-unmask</th>\n",
       "      <td>0.277</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.789</td>\n",
       "      <td>71882.842</td>\n",
       "      <td>0.000</td>\n",
       "      <td>184.481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-4-unmask</th>\n",
       "      <td>0.169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.916</td>\n",
       "      <td>36097.789</td>\n",
       "      <td>0.000</td>\n",
       "      <td>108.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o3</th>\n",
       "      <td>0.091</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.611</td>\n",
       "      <td>16758.053</td>\n",
       "      <td>11331.368</td>\n",
       "      <td>106.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o4-mini</th>\n",
       "      <td>0.111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.111</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.415</td>\n",
       "      <td>6614.211</td>\n",
       "      <td>5318.737</td>\n",
       "      <td>46.503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Avg Accuracy  Std Accuracy  Best Accuracy  \\\n",
       "Model                                                         \n",
       "Gemini 2.5               0.062           NaN          0.062   \n",
       "claude-37-unmask         0.277           NaN          0.277   \n",
       "claude-4-unmask          0.169           NaN          0.169   \n",
       "o3                       0.091           NaN          0.091   \n",
       "o4-mini                  0.111           NaN          0.111   \n",
       "\n",
       "                  Avg Difficulty-Weighted  Best Difficulty-Weighted  \\\n",
       "Model                                                                 \n",
       "Gemini 2.5                          0.040                     0.333   \n",
       "claude-37-unmask                    0.252                     0.833   \n",
       "claude-4-unmask                     0.142                     0.585   \n",
       "o3                                  0.079                     0.667   \n",
       "o4-mini                             0.111                     1.000   \n",
       "\n",
       "                  Avg Response Rate  Avg Output Tokens  Avg Reasoning Tokens  \\\n",
       "Model                                                                          \n",
       "Gemini 2.5                    0.430          22270.368              2575.263   \n",
       "claude-37-unmask              0.789          71882.842                 0.000   \n",
       "claude-4-unmask               0.916          36097.789                 0.000   \n",
       "o3                            0.611          16758.053             11331.368   \n",
       "o4-mini                       0.415           6614.211              5318.737   \n",
       "\n",
       "                  Avg Runtime (min)  \n",
       "Model                                \n",
       "Gemini 2.5                  172.098  \n",
       "claude-37-unmask            184.481  \n",
       "claude-4-unmask             108.757  \n",
       "o3                          106.795  \n",
       "o4-mini                      46.503  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not df.empty:\n",
    "    model_stats = get_model_summary_stats(df)\n",
    "    print(\"\\n=== MODEL SUMMARY STATISTICS ===\")\n",
    "    display(model_stats.round(3))\n",
    "else:\n",
    "    print(\"No data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Per-Paper Statistics\n",
    "\n",
    "Performance breakdown by paper across all models and runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    paper_stats = get_per_paper_stats(df)\n",
    "    print(\"\\n=== PER-PAPER STATISTICS ===\")\n",
    "    display(paper_stats.round(3))\n",
    "else:\n",
    "    print(\"No data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Accuracy by Model and Paper\n",
    "\n",
    "Average accuracy for each model on each paper (aggregated across runs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    accuracy_table = aggregate_runs(df, \"accuracy\", \"mean\")\n",
    "    print(\"\\n=== ACCURACY BY MODEL AND PAPER (Mean across runs) ===\")\n",
    "    display(accuracy_table.round(3))\n",
    "else:\n",
    "    print(\"No data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Difficulty-Weighted Accuracy\n",
    "\n",
    "Difficulty-weighted scores accounting for task complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    difficulty_weighted_table = aggregate_runs(df, \"difficulty_weighted_accuracy\", \"mean\")\n",
    "    print(\"\\n=== DIFFICULTY-WEIGHTED ACCURACY BY MODEL AND PAPER ===\")\n",
    "    display(difficulty_weighted_table.round(3))\n",
    "else:\n",
    "    print(\"No data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Best Run Performance\n",
    "\n",
    "Best accuracy achieved by each model on each paper (max across runs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    best_accuracy_table = aggregate_runs(df, \"accuracy\", \"max\")\n",
    "    print(\"\\n=== BEST ACCURACY BY MODEL AND PAPER (Max across runs) ===\")\n",
    "    display(best_accuracy_table.round(3))\n",
    "else:\n",
    "    print(\"No data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Token Usage Statistics\n",
    "\n",
    "Average token usage by model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    summary_df = df[df.index.get_level_values(\"task\") == \"_summary\"].copy()\n",
    "    \n",
    "    token_stats = summary_df.groupby(\"model\").agg({\n",
    "        \"input_tokens\": \"mean\",\n",
    "        \"output_tokens\": \"mean\",\n",
    "        \"reasoning_tokens\": \"mean\",\n",
    "        \"runtime_minutes\": \"mean\"\n",
    "    }).round(0)\n",
    "    \n",
    "    print(\"\\n=== TOKEN USAGE BY MODEL ===\")\n",
    "    display(token_stats)\n",
    "else:\n",
    "    print(\"No data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Task-Level Analysis\n",
    "\n",
    "Performance on individual tasks across all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    task_df = df[df.index.get_level_values(\"task\") != \"_summary\"].copy()\n",
    "    \n",
    "    if not task_df.empty:\n",
    "        task_stats = task_df.groupby([\"paper\", \"task\"]).agg({\n",
    "            \"task_score\": [\"mean\", \"std\", \"count\"],\n",
    "            \"task_difficulty\": \"first\"\n",
    "        }).round(3)\n",
    "        \n",
    "        print(\"\\n=== TASK-LEVEL STATISTICS (First 20 tasks) ===\")\n",
    "        display(task_stats.head(20))\n",
    "    else:\n",
    "        print(\"No task-level data available\")\n",
    "else:\n",
    "    print(\"No data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Export Tables\n",
    "\n",
    "Save tables to CSV files for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    output_dir = Path(\"table_outputs\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    model_stats.to_csv(output_dir / \"model_summary.csv\")\n",
    "    paper_stats.to_csv(output_dir / \"paper_summary.csv\")\n",
    "    accuracy_table.to_csv(output_dir / \"accuracy_by_model_paper.csv\")\n",
    "    difficulty_weighted_table.to_csv(output_dir / \"difficulty_weighted_accuracy.csv\")\n",
    "    \n",
    "    print(f\"\\nTables exported to {output_dir}/\")\n",
    "    print(\"  - model_summary.csv\")\n",
    "    print(\"  - paper_summary.csv\")\n",
    "    print(\"  - accuracy_by_model_paper.csv\")\n",
    "    print(\"  - difficulty_weighted_accuracy.csv\")\n",
    "else:\n",
    "    print(\"No data to export\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
